LORA

Low Rank Adaptation

Important Links
https://github.com/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb

IMAGE PROCESSOR :-
(https://huggingface.co/docs/transformers/main/en/main_classes/image_processor)
An image processor is in charge of preparing input features for vision models and post processing their outputs. 
This includes transformations such as resizing, normalization, and conversion to PyTorch, TensorFlow, Flax and Numpy tensors. 
It may also include model specific post-processing such as converting logits to segmentation masks.

AutoProcessor
(https://huggingface.co/docs/transformers/en/autoclass_tutorial)
Multimodal tasks require a processor that combines two types of preprocessing tools. For example, the LayoutLMV2 model requires an image processor to handle images and a tokenizer to handle text; a processor combines both of them.

Load a processor with AutoProcessor.from_pretrained():

Copied
from transformers import AutoProcessor

processor = AutoProcessor.from_pretrained("microsoft/layoutlmv2-base-uncased")


AutoModelforCasualLM :

This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created with the from_pretrained() class method or the from_config() class method.
This class cannot be instantiated directly using __init__() (throws an error).

model = "google-bert/bert-base-cased"
model_auto=AutoModelForCausalLM.from_pretrained(model)

This will download the model into .cache directory.
Normally in any model we will have some config.json files and model/safetensor files

In Google colab you will find the .cache directory stored inside /root folder.
Inside the root folder you will find the folders for each model.
